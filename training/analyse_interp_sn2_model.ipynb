{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from minimal_basis.dataset.dataset_reaction import ReactionDataset\n",
    "from minimal_basis.transforms.absolute import Absolute\n",
    "\n",
    "from utils import (\n",
    "    get_test_data_path,\n",
    "    get_validation_data_path,\n",
    "    get_train_data_path,\n",
    "    read_inputs_yaml,\n",
    ")\n",
    "\n",
    "from ase import units as ase_units\n",
    "from ase.data import atomic_numbers, atomic_names\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import wandb\n",
    "run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = read_inputs_yaml(os.path.join(\"config\", \"interp_sn2_model.yaml\"))\n",
    "\n",
    "train_json_filename = inputs[\"train_json\"]\n",
    "validate_json_filename = inputs[\"validate_json\"]\n",
    "kwargs_dataset = inputs[\"dataset_options\"]\n",
    "kwargs_dataset[\"use_minimal_basis_node_features\"] = inputs[\n",
    "    \"use_minimal_basis_node_features\"\n",
    "]\n",
    "\n",
    "train_dataset = ReactionDataset( \n",
    "    root=get_train_data_path(),\n",
    "    filename=train_json_filename,\n",
    "    basis_filename=inputs[\"basis_file\"],\n",
    "    **kwargs_dataset\n",
    ")\n",
    "\n",
    "validation_dataset = ReactionDataset(\n",
    "    root=get_validation_data_path(),\n",
    "    filename=validate_json_filename,\n",
    "    basis_filename=inputs[\"basis_file\"],\n",
    "    **kwargs_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mae_norms = []\n",
    "all_mae_norms_linear_interp = []\n",
    "\n",
    "for idx, data in enumerate(train_loader):\n",
    "\n",
    "    interpolated_ts_coords = data.pos_interpolated_transition_state.detach().numpy()\n",
    "    real_ts_coords = data.pos_transition_state.detach().numpy()\n",
    "    difference_ts_coords = interpolated_ts_coords - real_ts_coords\n",
    "    linear_interp_coords = ( data.pos + data.pos_final_state ) / 2\n",
    "    norm_difference_ts_coords = np.linalg.norm(difference_ts_coords, axis=1)\n",
    "    difference_linear_interp_coords = linear_interp_coords - real_ts_coords\n",
    "    norm_difference_linear_interp_coords = np.linalg.norm(difference_linear_interp_coords, axis=1)\n",
    "\n",
    "    # Mean absolute error\n",
    "    mae = np.mean(norm_difference_ts_coords)\n",
    "    all_mae_norms.append(mae)\n",
    "\n",
    "    mae_linear_interp = np.mean(norm_difference_linear_interp_coords)\n",
    "    all_mae_norms_linear_interp.append(mae_linear_interp)\n",
    "\n",
    "    # Plot the real and interpolated TS structures\n",
    "    # with two different colors on the same plot\n",
    "    # fig = px.scatter_3d(\n",
    "    #     x=np.concatenate((real_ts_coords[:, 0], interpolated_ts_coords[:, 0])),\n",
    "    #     y=np.concatenate((real_ts_coords[:, 1], interpolated_ts_coords[:, 1])),\n",
    "    #     z=np.concatenate((real_ts_coords[:, 2], interpolated_ts_coords[:, 2])),\n",
    "    #     color=np.concatenate((np.zeros(len(real_ts_coords)), np.ones(len(interpolated_ts_coords)))),\n",
    "    # )\n",
    "\n",
    "    # # Set the title of the plot as the mean absolute error\n",
    "    # fig.update_layout(title=f\"MAE of structure prediction: {mae:.3f} Å\")\n",
    "    # fig.write_html(f\"plots/hamiltonian_model/interpolated_ts_{idx}_mae_{mae:.3f}.html\")\n",
    "\n",
    "# Plot a histogram of the MAE\n",
    "fig = px.histogram(x=all_mae_norms, nbins=20, template=\"simple_white\")\n",
    "# On the same plot, plot the histogram of the MAE for the linear interpolation\n",
    "# fig.add_trace(\n",
    "#     go.Histogram(\n",
    "#         x=all_mae_norms_linear_interp,\n",
    "#         nbinsx=20,\n",
    "#         name=\"Linear interpolation\",\n",
    "#         opacity=0.75,\n",
    "#     )\n",
    "# )\n",
    "fig.update_layout(title=\"MAE structure prediction (Å)\")\n",
    "fig.update_xaxes(title_text=\"MAE (Å)\")\n",
    "fig.update_yaxes(title_text=\"Frequency\")\n",
    "# fig.write_html(\"plots/hamiltonian_model/interpolated_ts_mae_histogram.html\")\n",
    "\n",
    "# Reduce the aspect ratio\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_coeff = run.use_artifact('sudarshanvj/reaction/reaction_model:v38', type='model')\n",
    "artifact_dir_coeff = artifact_coeff.download()\n",
    "artifact_barrier = run.use_artifact('sudarshanvj/reaction/reaction_model:v39', type='model')\n",
    "artifact_dir_barrier = artifact_barrier.download()\n",
    "artifact_forces = run.use_artifact('sudarshanvj/reaction/reaction_model:v16', type='model')\n",
    "artifact_dir_forces = artifact_forces.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(artifact_dir_coeff, \"reaction_model.pt\"), map_location=torch.device('cpu'))\n",
    "\n",
    "for idx, data in enumerate(validation_loader):\n",
    "    output = model(data)\n",
    "    output = output.detach().numpy()\n",
    "    sum_squares_ouput = np.sum(output**2)\n",
    "    print(f\"Sum of squares of output: {sum_squares_ouput:.3f}\")\n",
    "\n",
    "    expected = data.x_transition_state.detach().numpy()\n",
    "    expected = np.abs(expected)\n",
    "    sum_squares_expected = np.sum(expected**2)\n",
    "    print(f\"Sum of squares of expected: {sum_squares_expected:.3f}\")\n",
    "\n",
    "    difference = output - expected\n",
    "    difference = np.abs(difference)\n",
    "    sum_differences = np.sum(np.abs(difference))\n",
    "    sumsq_differences = np.sum(difference**2)\n",
    "    print(f\"Sum of differences: {sum_differences:.3f}\")\n",
    "    print(f\"Sum of squares of differences: {sumsq_differences:.3f}\")\n",
    "    print(f\"Max differences\", np.max(np.abs(difference)))\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(7,5),  sharey=True, sharex=True, facecolor='w')\n",
    "    cax = axs[0].imshow(output, cmap=\"cividis\")\n",
    "    fig.colorbar(cax, ax=axs[0])\n",
    "    axs[0].set_title(r\"$\\mathbf{C}_{\\mathrm{model}}$\")\n",
    "    cax = axs[1].imshow(expected, cmap=\"cividis\")\n",
    "    fig.colorbar(cax, ax=axs[1])\n",
    "    cax.set_clim(axs[0].get_images()[0].get_clim())\n",
    "    axs[1].set_title(r\"$\\mathbf{C}_{\\mathrm{DFT}}$\")\n",
    "    # cax = axs[2].imshow(difference, cmap=\"Blues\")\n",
    "    # fig.colorbar(cax, ax=axs[2])\n",
    "    # axs[2].set_title(r\"$\\left | \\mathbf{C}_{\\mathrm{model}} - \\mathbf{C}_{\\mathrm{DFT}} \\right | $\")\n",
    "\n",
    "    tickvals = data.species.view(-1).detach().numpy().flatten()\n",
    "    tickvals_species = [atomic_names[int(tickval)] for tickval in tickvals]\n",
    "    axs[0].set_yticks(np.arange(len(tickvals)))\n",
    "    axs[0].set_yticklabels(tickvals_species)\n",
    "    axs[1].set_yticks(np.arange(len(tickvals)))\n",
    "    axs[1].set_yticklabels(tickvals_species)\n",
    "    # axs[2].set_yticks(np.arange(len(tickvals)))\n",
    "    # axs[2].set_yticklabels(tickvals_species)\n",
    "    axs[0].set_xticks(np.arange(35))\n",
    "    # axs[0].set_xticks(np.arange(4))\n",
    "    axs[0].set_xticklabels(5 *[\"s\"] + 12*[\"p\"] + 3*[\"s\" , \"d\" , \"d\" , \"d\" , \"d\" , \"d\"])\n",
    "    # axs[0].set_xticklabels(1*[\"s\"] + 3*[\"p\"])\n",
    "    # axs[0].set_ylabel(\"Atom Number\")\n",
    "    # axs[1].set_ylabel(\"Atom Number\")\n",
    "    # axs[2].set_ylabel(\"Atom Number\")\n",
    "    fig.tight_layout()\n",
    "    # Improve dpi\n",
    "    fig.set_dpi(100)\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the sum of squares of the coefficient matrix\n",
    "model = torch.load(os.path.join(artifact_dir_coeff, \"reaction_model.pt\"), map_location=torch.device('cpu'))\n",
    "\n",
    "from ase.data import chemical_symbols\n",
    "from pyscf import gto\n",
    "from pyscf.dft.numint import eval_ao\n",
    "from ase import Atoms\n",
    "from ase.io.cube import write_cube\n",
    "\n",
    "for idx, data in enumerate(validation_loader):\n",
    "\n",
    "    basis_mask = data.basis_mask.detach().numpy()\n",
    "\n",
    "    output = model(data)\n",
    "    output = output.detach().numpy()\n",
    "    output = output.flatten()[basis_mask.flatten()]\n",
    "\n",
    "    expected = data.x_transition_state.detach().numpy()\n",
    "    expected = expected.flatten()[basis_mask.flatten()]\n",
    "\n",
    "    real_ts_coords = data.pos_transition_state.detach().numpy()\n",
    "    interpolated_ts_coords = data.pos_interpolated_transition_state.detach().numpy()\n",
    "\n",
    "    species = data.species.squeeze().detach().numpy()\n",
    "    species_names = [chemical_symbols[int(species[i])] for i in range(len(species))]\n",
    "\n",
    "    atoms_real_input = \"\"\n",
    "    for i in range(len(species)):\n",
    "        atoms_real_input += f\"{species_names[i]} {real_ts_coords[i][0]} {real_ts_coords[i][1]} {real_ts_coords[i][2]}; \"\n",
    "    atoms_input = atoms_real_input[:-2]\n",
    "    pyscf_mol = gto.M(atom=atoms_input, basis='6-31g*', charge=-1, cart=True)\n",
    "    atoms = Atoms(symbols=species_names, positions=real_ts_coords)\n",
    "\n",
    "    atoms_interpolated_input = \"\"\n",
    "    for i in range(len(species)):\n",
    "        atoms_interpolated_input += f\"{species_names[i]} {interpolated_ts_coords[i][0]} {interpolated_ts_coords[i][1]} {interpolated_ts_coords[i][2]}; \"\n",
    "    atoms_input = atoms_interpolated_input[:-2]\n",
    "    pyscf_mol_interpolated = gto.M(atom=atoms_input, basis='6-31g*', charge=-1, cart=True)\n",
    "    interpolated_atoms = Atoms(symbols=species_names, positions=interpolated_ts_coords)\n",
    "\n",
    "    x = np.linspace(np.min(real_ts_coords[:,0]) - 5, np.max(real_ts_coords[:,0]) + 5, 100)\n",
    "    y = np.linspace(np.min(real_ts_coords[:,1]) - 5, np.max(real_ts_coords[:,1]) + 5, 100)\n",
    "    z = np.linspace(np.min(real_ts_coords[:,2]) - 5, np.max(real_ts_coords[:,2]) + 5, 100)\n",
    "    grid = np.array(np.meshgrid(x, y, z)).T.reshape(-1, 3)\n",
    "\n",
    "    atomic_orbital_grid = eval_ao(pyscf_mol, grid, deriv=0)\n",
    "    predicted_orbital_grid = eval_ao(pyscf_mol_interpolated, grid, deriv=0) \n",
    "\n",
    "    sq_mo_diagonal = np.dot(atomic_orbital_grid**2, expected**2)\n",
    "    predicted_sq_mo_diagonal = np.dot(predicted_orbital_grid**2, output**2)\n",
    "    \n",
    "    error_sq_mo_diagonal = np.abs(sq_mo_diagonal - predicted_sq_mo_diagonal)\n",
    "    print(np.max(error_sq_mo_diagonal))\n",
    "\n",
    "    # Average out the xy dimensions and plot both the real and predicted orbitals\n",
    "    reshaped_sq_mo_diagonal = sq_mo_diagonal.reshape(len(x), len(y), len(z))\n",
    "    reshaped_predicted_sq_mo_diagonal = predicted_sq_mo_diagonal.reshape(len(x), len(y), len(z))\n",
    "    # Write out the cube files\n",
    "    atoms.set_cell([np.max(x) - np.min(x), np.max(y) - np.min(y), np.max(z) - np.min(z)])\n",
    "    interpolated_atoms.set_cell([np.max(x) - np.min(x), np.max(y) - np.min(y), np.max(z) - np.min(z)])\n",
    "    # write_cube(open(\"output/real.cube\", \"w\"), atoms, reshaped_sq_mo_diagonal, origin=(np.min(x), np.min(y), np.min(z)))\n",
    "    # write_cube(open(\"output/predicted.cube\", \"w\"), interpolated_atoms, reshaped_predicted_sq_mo_diagonal, origin=(np.min(x), np.min(y), np.min(z)))\n",
    "\n",
    "    xy_averaged_sq_mo_diagonal = np.mean(reshaped_sq_mo_diagonal, axis=(0,1))\n",
    "    xy_averaged_predicted_sq_mo_diagonal = np.mean(reshaped_predicted_sq_mo_diagonal, axis=(0,1))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(4.5,4))\n",
    "    axs.plot(z, xy_averaged_sq_mo_diagonal, label=\"DFT\")\n",
    "    axs.plot(z, xy_averaged_predicted_sq_mo_diagonal, label=\"Model\")\n",
    "    axs.set_xlabel(\"z (Å)\")\n",
    "    axs.set_ylabel(r\"xy averaged $\\left | \\psi_i \\right |^2$\")\n",
    "    axs.legend()\n",
    "    fig.set_dpi(150)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.sum(sq_mo_diagonal))\n",
    "# print(np.sum(predicted_sq_mo_diagonal))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)\n",
    "print(reshaped_sq_mo_diagonal.shape)\n",
    "\n",
    "print(\"Maximum of the sq_mo_diagonal\", np.max(sq_mo_diagonal))\n",
    "print(\"Maximum of the predicted_sq_mo_diagonal\", np.max(predicted_sq_mo_diagonal))\n",
    "print(\"Minimum of the sq_mo_diagonal\", np.min(sq_mo_diagonal))\n",
    "print(\"Minimum of the predicted_sq_mo_diagonal\", np.min(predicted_sq_mo_diagonal))\n",
    "mlab.figure(bgcolor=(1,1,1))\n",
    "# mlab.pipeline.volume(mlab.pipeline.scalar_field(reshaped_sq_mo_diagonal), vmin=0, vmax=0.0001, )\n",
    "# Plot the predicted orbitals in the same figure with another color\n",
    "mlab.pipeline.volume(mlab.pipeline.scalar_field(reshaped_predicted_sq_mo_diagonal), vmin=0, vmax=0.0001, color=(1,0,0))\n",
    "# Save the figure\n",
    "# mlab.savefig(\"output/real.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the model\n",
    "# model = torch.load(\"output/reaction_model.pt\")\n",
    "model = torch.load(os.path.join(artifact_dir_barrier, \"reaction_model.pt\"), map_location=torch.device('cpu'))\n",
    "\n",
    "outputs = []\n",
    "expecteds = []\n",
    "\n",
    "for idx, data in enumerate(validation_loader):\n",
    "    output = model(data)\n",
    "    output = output.mean(dim=1)\n",
    "    \n",
    "    output = output.detach().numpy()\n",
    "    expected = data.total_energy_transition_state - data.total_energy\n",
    "    expected = expected.detach().numpy()\n",
    "\n",
    "    outputs.append(output[0])\n",
    "    expecteds.append(expected[0])\n",
    "\n",
    "\n",
    "# Make a parity plot of the output vs. expected\n",
    "outputs = np.array(outputs).flatten()\n",
    "expecteds = np.array(expecteds).flatten()\n",
    "outputs *= ase_units.Ha\n",
    "expecteds *= ase_units.Ha\n",
    "\n",
    "# Remove entries from output and expected that less than 0\n",
    "# idx_to_remove = np.where(expecteds < 0)[0]\n",
    "# outputs = np.delete(outputs, idx_to_remove)\n",
    "# expecteds = np.delete(expecteds, idx_to_remove)\n",
    "\n",
    "\n",
    "# Number of points\n",
    "print(f\"Number of points: {len(outputs)}\")\n",
    "# Determine the mean absolute error\n",
    "mae = np.mean(np.abs(outputs - expecteds))\n",
    "print(f\"Mean absolute error: {mae:.3f} eV\")\n",
    "\n",
    "fig = px.scatter(x=expecteds, y=outputs, template=\"simple_white\")\n",
    "# fig.update_layout(title=\"Parity plot of the output vs. expected barriers\")\n",
    "fig.update_xaxes(title_text=\"DFT Computed Barrier (eV)\")\n",
    "fig.update_yaxes(title_text=\"Model Output Barrier (eV)\")\n",
    "# Set x and y axes to be greater than 0\n",
    "# fig.update_xaxes(range=[0, outputs.max()])\n",
    "# fig.update_yaxes(range=[0, outputs.max()])\n",
    "# Draw the parity line\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=outputs.min(),\n",
    "    y0=outputs.min(),\n",
    "    x1=outputs.max(),\n",
    "    y1=outputs.max(),\n",
    "    line=dict(\n",
    "        color=\"Red\",\n",
    "        width=4,\n",
    "        dash=\"dashdot\",\n",
    "    )\n",
    ")\n",
    "# Reduce the aspect ratio\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c0de598c4e13c0bc0daa0f1515205270a88f8656cf701de288f6c6743b0ef60d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
