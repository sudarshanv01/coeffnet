{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msudarshanvj\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sudarshanvijay/Documents/projects/18_SEI/minimal-basis/training/wandb/run-20230227_140539-gsrvc3uj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sudarshanvj/hamiltonian/runs/gsrvc3uj' target=\"_blank\">eternal-frog-22</a></strong> to <a href='https://wandb.ai/sudarshanvj/hamiltonian' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sudarshanvj/hamiltonian' target=\"_blank\">https://wandb.ai/sudarshanvj/hamiltonian</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sudarshanvj/hamiltonian/runs/gsrvc3uj' target=\"_blank\">https://wandb.ai/sudarshanvj/hamiltonian/runs/gsrvc3uj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from e3nn import o3\n",
    "from minimal_basis.dataset.dataset_hamiltonian import HamiltonianDataset\n",
    "from minimal_basis.model.model_hamiltonian import (\n",
    "    EquivariantConv,\n",
    "    SimpleHamiltonianModel,\n",
    ")\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from utils import (\n",
    "    get_test_data_path,\n",
    "    get_validation_data_path,\n",
    "    get_train_data_path,\n",
    "    read_inputs_yaml,\n",
    ")\n",
    "from ase import units as ase_units\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import wandb\n",
    "wandb_run = wandb.init(project=\"hamiltonian\", entity=\"sudarshanvj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:minimal_basis.dataset.dataset_hamiltonian:Successfully loaded json file with data.\n",
      "INFO:minimal_basis.dataset.dataset_hamiltonian:Successfully loaded json file with basis information.\n",
      "INFO:minimal_basis.dataset.dataset_hamiltonian:Parsing basis information.\n",
      "INFO:minimal_basis.dataset.dataset_hamiltonian:Parsing basis information from ./input_files/6-31G_star.json\n",
      "INFO:minimal_basis.dataset.dataset_hamiltonian:Successfully loaded json file with data.\n",
      "INFO:minimal_basis.dataset.dataset_hamiltonian:Successfully loaded json file with basis information.\n",
      "INFO:minimal_basis.dataset.dataset_hamiltonian:Parsing basis information.\n",
      "INFO:minimal_basis.dataset.dataset_hamiltonian:Parsing basis information from ./input_files/6-31G_star.json\n"
     ]
    }
   ],
   "source": [
    "inputs = read_inputs_yaml(os.path.join(\"input_files\", \"hamiltonian_model.yaml\"))\n",
    "\n",
    "train_json_filename = inputs[\"debug_train_json\"]\n",
    "validate_json_filename = inputs[\"debug_validate_json\"]\n",
    "\n",
    "train_dataset = HamiltonianDataset(\n",
    "    root=get_train_data_path(),\n",
    "    filename=train_json_filename,\n",
    "    basis_file=inputs[\"basis_file\"],\n",
    ")\n",
    "validation_dataset = HamiltonianDataset(\n",
    "    root=get_validation_data_path(),\n",
    "    filename=validate_json_filename,\n",
    "    basis_file=inputs[\"basis_file\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleHamiltonianModel(\n",
       "  (conv): EquivariantConv(\n",
       "    (tp): FullyConnectedTensorProduct(14x0e x 14x0e -> 20x0e | 3920 paths | 3920 weights)\n",
       "    (fc): FullyConnectedNet[10, 64, 3920]\n",
       "  )\n",
       "  (conv_global): EquivariantConv(\n",
       "    (tp): FullyConnectedTensorProduct(14x0e x 14x0e -> 20x0e | 3920 paths | 3920 weights)\n",
       "    (fc): FullyConnectedNet[10, 64, 3920]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model\n",
    "artifact = wandb_run.use_artifact('sudarshanvj/hamiltonian/hamiltonian_model:v5', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "model = torch.load(os.path.join(artifact_dir, \"hamiltonian_model.pt\"), map_location=torch.device('cpu') )\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Incorrect last dimension for x",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/sudarshanvijay/Documents/projects/18_SEI/minimal-basis/training/analyse_hamiltonian_dataset.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudarshanvijay/Documents/projects/18_SEI/minimal-basis/training/analyse_hamiltonian_dataset.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     fig\u001b[39m.\u001b[39mwrite_html(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mplots/hamiltonian_model/interpolated_ts_\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m_mae_\u001b[39m\u001b[39m{\u001b[39;00mmae\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.html\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudarshanvijay/Documents/projects/18_SEI/minimal-basis/training/analyse_hamiltonian_dataset.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     real_y \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39my\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sudarshanvijay/Documents/projects/18_SEI/minimal-basis/training/analyse_hamiltonian_dataset.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     predicted_y \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudarshanvijay/Documents/projects/18_SEI/minimal-basis/training/analyse_hamiltonian_dataset.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     output_comparison\u001b[39m.\u001b[39mappend([real_y\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(), predicted_y\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudarshanvijay/Documents/projects/18_SEI/minimal-basis/training/analyse_hamiltonian_dataset.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Plot a histogram of the MAE\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/molml/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/projects/18_SEI/minimal-basis/src/minimal_basis/model/model_hamiltonian.py:190\u001b[0m, in \u001b[0;36mSimpleHamiltonianModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    185\u001b[0m pos \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mpos\n\u001b[1;32m    187\u001b[0m f_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(\n\u001b[1;32m    188\u001b[0m     f_nodes_IS, f_nodes_FS, edge_index_TS_interp, pos_TS_interp\n\u001b[1;32m    189\u001b[0m )\n\u001b[0;32m--> 190\u001b[0m g_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(\n\u001b[1;32m    191\u001b[0m     f_global_IS[data\u001b[39m.\u001b[39mbatch],\n\u001b[1;32m    192\u001b[0m     f_global_FS[data\u001b[39m.\u001b[39mbatch],\n\u001b[1;32m    193\u001b[0m     edge_index_TS_interp,\n\u001b[1;32m    194\u001b[0m     pos_TS_interp,\n\u001b[1;32m    195\u001b[0m )\n\u001b[1;32m    197\u001b[0m f_output_IS \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(f_nodes_IS, f_nodes_IS, edge_index_IS, pos)\n\u001b[1;32m    198\u001b[0m g_output_IS \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(\n\u001b[1;32m    199\u001b[0m     f_global_IS[data\u001b[39m.\u001b[39mbatch], f_global_IS[data\u001b[39m.\u001b[39mbatch], edge_index_IS, pos\n\u001b[1;32m    200\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/molml/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/projects/18_SEI/minimal-basis/src/minimal_basis/model/model_hamiltonian.py:149\u001b[0m, in \u001b[0;36mEquivariantConv.forward\u001b[0;34m(self, f_1, f_2, edge_index, pos)\u001b[0m\n\u001b[1;32m    138\u001b[0m edge_length_embedding \u001b[39m=\u001b[39m soft_one_hot_linspace(\n\u001b[1;32m    139\u001b[0m     edge_vec\u001b[39m.\u001b[39mnorm(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    140\u001b[0m     start\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m     cutoff\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    145\u001b[0m )\n\u001b[1;32m    147\u001b[0m weights_from_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(edge_length_embedding)\n\u001b[0;32m--> 149\u001b[0m f_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtp(f_1[row], f_2[row], weights_from_embedding)\n\u001b[1;32m    151\u001b[0m \u001b[39m# Mean the output over the edges to get one output per node\u001b[39;00m\n\u001b[1;32m    152\u001b[0m f_output \u001b[39m=\u001b[39m scatter_mean(f_output, col, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/molml/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/molml/lib/python3.9/site-packages/e3nn/o3/_tensor_product/_tensor_product.py:537\u001b[0m, in \u001b[0;36mTensorProduct.forward\u001b[0;34m(self, x, y, weight)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, y, weight: Optional[torch\u001b[39m.\u001b[39mTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    515\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Evaluate :math:`w x \\otimes y`.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \n\u001b[1;32m    517\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39m        tensor of shape ``(..., irreps_out.dim)``\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 537\u001b[0m     \u001b[39massert\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in1_dim, \u001b[39m\"\u001b[39m\u001b[39mIncorrect last dimension for x\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    538\u001b[0m     \u001b[39massert\u001b[39;00m y\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in2_dim, \u001b[39m\"\u001b[39m\u001b[39mIncorrect last dimension for y\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m     \u001b[39m# - PROFILER - with torch.autograd.profiler.record_function(self._profiling_str):\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Incorrect last dimension for x"
     ]
    }
   ],
   "source": [
    "all_mae_norms = []\n",
    "output_comparison = [] \n",
    "\n",
    "for idx, data in enumerate(train_loader):\n",
    "\n",
    "    interpolated_ts_coords = data.pos_interpolated_TS.detach().numpy()\n",
    "    real_ts_coords = data.pos_real_TS\n",
    "    real_ts_coords = np.array(real_ts_coords[0])\n",
    "\n",
    "    difference_ts_coords = interpolated_ts_coords - real_ts_coords\n",
    "\n",
    "    norm_difference_ts_coords = np.linalg.norm(difference_ts_coords, axis=1)\n",
    "    # Mean absolute error\n",
    "    mae = np.mean(norm_difference_ts_coords)\n",
    "    all_mae_norms.append(mae)\n",
    "\n",
    "    # Plot the real and interpolated TS structures\n",
    "    # with two different colors on the same plot\n",
    "    fig = px.scatter_3d(\n",
    "        x=np.concatenate((real_ts_coords[:, 0], interpolated_ts_coords[:, 0])),\n",
    "        y=np.concatenate((real_ts_coords[:, 1], interpolated_ts_coords[:, 1])),\n",
    "        z=np.concatenate((real_ts_coords[:, 2], interpolated_ts_coords[:, 2])),\n",
    "        color=np.concatenate((np.zeros(len(real_ts_coords)), np.ones(len(interpolated_ts_coords)))),\n",
    "    )\n",
    "    # Set the title of the plot as the mean absolute error\n",
    "    fig.update_layout(title=f\"MAE: {mae:.3f} Ã…\")\n",
    "    fig.write_html(f\"plots/hamiltonian_model/interpolated_ts_{idx}_mae_{mae:.3f}.html\")\n",
    "\n",
    "    real_y = data.y\n",
    "    predicted_y = model(data)\n",
    "    output_comparison.append([real_y.detach().numpy(), predicted_y.detach().numpy()])\n",
    "\n",
    "# Plot a histogram of the MAE\n",
    "fig = px.histogram(x=all_mae_norms, nbins=20)\n",
    "fig.update_layout(title=\"Histogram of MAE\")\n",
    "fig.show()\n",
    "\n",
    "output_comparison = np.array(output_comparison).T\n",
    "output_comparison = np.squeeze(output_comparison)\n",
    "# Multiply the energies with the Hartree to eV conversion factor\n",
    "output_comparison[0] *= ase_units.Hartree\n",
    "output_comparison[1] *= ase_units.Hartree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a parity plot of the real and predicted energies\n",
    "fig = px.scatter(\n",
    "    x=output_comparison[0].flatten(),\n",
    "    y=output_comparison[1].flatten(),\n",
    ")\n",
    "# Draw a parity x=y line\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0= min(output_comparison[0].min(), output_comparison[1].min()),\n",
    "    y0= min(output_comparison[0].min(), output_comparison[1].min()),\n",
    "    x1 = max(output_comparison[0].max(), output_comparison[1].max()),\n",
    "    y1 = max(output_comparison[0].max(), output_comparison[1].max()),\n",
    "    line=dict(\n",
    "        color=\"Red\",\n",
    "        width=4,\n",
    "        dash=\"dashdot\",\n",
    "    )\n",
    ")\n",
    "# Make the aspect ratio of the plot equa\n",
    "fig.update_xaxes(scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.update_layout(title=\"Parity plot of real and predicted energies\")\n",
    "fig.update_xaxes(title_text=\"Real energies (eV)\")\n",
    "fig.update_yaxes(title_text=\"Predicted energies (eV)\")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0de598c4e13c0bc0daa0f1515205270a88f8656cf701de288f6c6743b0ef60d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
